{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the image\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg\"\n",
    "\n",
    "# Add headers to mimic a browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Send the request with headers\n",
    "response = requests.get(url, headers=headers, stream=True)\n",
    "\n",
    "# Check for a successful response\n",
    "if response.status_code == 200:\n",
    "    # Load the image into PIL directly without saving to disk\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "else:\n",
    "    print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "    \n",
    "# Define a transform for the input image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained ResNet50 model\n",
    "model = models.resnet50(weights='ResNet50_Weights.DEFAULT').cuda()\n",
    "input_tensor = preprocess(img).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: pug\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::conv2d         0.15%     241.807us        68.81%     111.482ms       2.103ms       0.000us         0.00%       4.091ms      77.190us            53  \n",
      "                                      aten::convolution         0.40%     643.756us        68.66%     111.240ms       2.099ms       0.000us         0.00%       4.091ms      77.190us            53  \n",
      "                                     aten::_convolution         0.28%     452.992us        68.26%     110.596ms       2.087ms       0.000us         0.00%       4.091ms      77.190us            53  \n",
      "                                aten::cudnn_convolution        44.64%      72.323ms        67.98%     110.143ms       2.078ms       4.091ms        80.84%       4.091ms      77.190us            53  \n",
      "                                       cudaLaunchKernel        36.35%      58.896ms        36.35%      58.896ms     290.128us       0.000us         0.00%       0.000us       0.000us           203  \n",
      "                                            aten::relu_         0.52%     849.623us         8.59%      13.922ms     284.116us       0.000us         0.00%     215.621us       4.400us            49  \n",
      "                                       aten::clamp_min_         0.35%     566.496us         8.07%      13.072ms     266.777us     215.621us         4.26%     215.621us       4.400us            49  \n",
      "                                   cudaGetSymbolAddress         6.23%      10.090ms         6.23%      10.090ms      10.090ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                       aten::batch_norm         0.10%     163.315us         5.54%       8.980ms     169.438us       0.000us         0.00%     417.359us       7.875us            53  \n",
      "                           aten::_batch_norm_impl_index         0.17%     276.594us         5.44%       8.817ms     166.356us       0.000us         0.00%     417.359us       7.875us            53  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 162.026ms\n",
      "Self CUDA time total: 5.061ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# Perform a single prediction\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "    record_shapes=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    output = model(input_tensor)\n",
    "    _, predicted_class = output.max(1)\n",
    "\n",
    "# Load the class labels\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "labels = requests.get(LABELS_URL).json()\n",
    "\n",
    "# Get the class label\n",
    "predicted_label = labels[predicted_class.item()]\n",
    "print(f\"Predicted class label: {predicted_label}\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time on GPU: 0.0090 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "trials = 100\n",
    "for _ in range(trials):\n",
    "    label = model(input_tensor)\n",
    "    assert label.argmax() == predicted_class\n",
    "end_time = time.time()\n",
    "\n",
    "avg_time_inference_gpu = (end_time - start_time) / trials\n",
    "print(f\"Average inference time on GPU: {avg_time_inference_gpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single training iteration completed.\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       cudaLaunchKernel        57.57%      73.468ms        57.57%      73.468ms     128.666us       0.000us         0.00%       0.000us       0.000us           571  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.73%     932.273us        21.59%      27.555ms     519.914us       0.000us         0.00%       8.765ms     165.377us            53  \n",
      "                                   ConvolutionBackward0         0.36%     460.123us        20.62%      26.309ms     496.390us       0.000us         0.00%       8.496ms     160.301us            53  \n",
      "                             aten::convolution_backward        10.83%      13.820ms        20.26%      25.849ms     487.708us       8.496ms        45.36%       8.496ms     160.301us            53  \n",
      "                                       aten::batch_norm         0.16%     209.331us        12.97%      16.544ms     312.160us       0.000us         0.00%       1.535ms      28.956us            53  \n",
      "                           aten::_batch_norm_impl_index         0.29%     366.133us        12.80%      16.335ms     308.210us       0.000us         0.00%       1.535ms      28.956us            53  \n",
      "                                 aten::cudnn_batch_norm         3.09%       3.947ms        12.51%      15.969ms     301.302us       1.535ms         8.19%       1.535ms      28.956us            53  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         0.07%      93.669us        10.34%      13.201ms      13.201ms       0.000us         0.00%      67.874us      67.874us             1  \n",
      "                               aten::cross_entropy_loss         0.05%      60.126us         9.84%      12.559ms      12.559ms       0.000us         0.00%       7.456us       7.456us             1  \n",
      "autograd::engine::evaluate_function: CudnnBatchNormB...         0.74%     942.708us         9.20%      11.739ms     221.495us       0.000us         0.00%       1.962ms      37.010us            53  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 127.607ms\n",
      "Self CUDA time total: 18.732ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set model to train mode\n",
    "model.train()\n",
    "\n",
    "# Create a dummy label (for ImageNet, valid class indices are 0 to 999)\n",
    "dummy_label = torch.tensor([0], dtype=torch.long, device='cuda')\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Profile a single training iteration\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log_train'),\n",
    "    record_shapes=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    # Forward pass\n",
    "    output = model(input_tensor)\n",
    "    loss = criterion(output, dummy_label)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Single training iteration completed.\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time on GPU: 0.0470 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time_gpu = time.time()\n",
    "trials = 100\n",
    "for _ in range(trials):\n",
    "    output = model(input_tensor)\n",
    "    loss = criterion(output, dummy_label)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "end_time_gpu = time.time()\n",
    "avg_time_train_gpu = (end_time_gpu - start_time_gpu) / trials\n",
    "print(f\"Average training time on GPU: {avg_time_train_gpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label on CPU: pug\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.36%     307.513us        83.41%      71.167ms       1.343ms            53  \n",
      "                aten::convolution         0.96%     819.516us        83.05%      70.860ms       1.337ms            53  \n",
      "               aten::_convolution         0.65%     551.267us        82.09%      70.040ms       1.322ms            53  \n",
      "         aten::mkldnn_convolution        80.51%      68.691ms        81.44%      69.489ms       1.311ms            53  \n",
      "                 aten::batch_norm         0.25%     211.849us         7.76%       6.617ms     124.852us            53  \n",
      "     aten::_batch_norm_impl_index         0.53%     454.165us         7.51%       6.405ms     120.855us            53  \n",
      "          aten::native_batch_norm         6.19%       5.285ms         6.87%       5.858ms     110.521us            53  \n",
      "                       aten::add_         3.22%       2.751ms         3.22%       2.751ms     171.955us            16  \n",
      "                      aten::relu_         0.92%     785.531us         2.36%       2.014ms      41.103us            49  \n",
      "                 aten::max_pool2d         0.01%       6.001us         2.08%       1.775ms       1.775ms             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 85.323ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Move model and tensor to CPU\n",
    "model_cpu = models.resnet50(weights='ResNet50_Weights.DEFAULT').cpu()\n",
    "model_cpu.eval()\n",
    "input_tensor_cpu = preprocess(img).unsqueeze(0).cpu()\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "    record_shapes=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    output_cpu = model_cpu(input_tensor_cpu)\n",
    "    _, predicted_class_cpu = output_cpu.max(1)\n",
    "\n",
    "predicted_label_cpu = labels[predicted_class_cpu.item()]\n",
    "print(f\"Predicted class label on CPU: {predicted_label_cpu}\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time on CPU: 0.0842 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure inference time on CPU\n",
    "start_time_cpu = time.time()\n",
    "trials = 100\n",
    "for _ in range(trials):\n",
    "    label = model_cpu(input_tensor_cpu)\n",
    "    assert label.argmax() == predicted_class  # Ensure same result as GPU\n",
    "end_time_cpu = time.time()\n",
    "avg_time_inference_cpu = (end_time_cpu - start_time_cpu) / trials\n",
    "print(f\"Average inference time on CPU: {avg_time_inference_cpu:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single training iteration completed.\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.38%       1.738ms        54.03%     246.707ms       4.655ms            53  \n",
      "                                   ConvolutionBackward0         0.16%     742.912us        52.80%     241.095ms       4.549ms            53  \n",
      "                             aten::convolution_backward        52.21%     238.395ms        52.64%     240.352ms       4.535ms            53  \n",
      "                                           aten::conv2d         0.11%     497.033us        28.72%     131.143ms       2.474ms            53  \n",
      "                                      aten::convolution         0.29%       1.308ms        28.61%     130.646ms       2.465ms            53  \n",
      "                                     aten::_convolution         0.20%     898.520us        28.32%     129.338ms       2.440ms            53  \n",
      "                               aten::mkldnn_convolution        27.81%     127.008ms        28.13%     128.439ms       2.423ms            53  \n",
      "                                             aten::add_         5.80%      26.494ms         5.80%      26.494ms     107.701us           246  \n",
      "                                Optimizer.step#SGD.step         0.62%       2.848ms         4.60%      21.016ms      21.016ms             1  \n",
      "                                       aten::batch_norm         0.07%     331.586us         3.56%      16.257ms     306.727us            53  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 456.636ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set model to train mode\n",
    "model_cpu.train()\n",
    "\n",
    "# Create a dummy label (for ImageNet, valid class indices are 0 to 999)\n",
    "dummy_label = torch.tensor([0], dtype=torch.long, device='cpu')\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_cpu.parameters(), lr=1e-3)\n",
    "\n",
    "# Profile a single training iteration\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log_train'),\n",
    "    record_shapes=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    # Forward pass\n",
    "    output = model_cpu(input_tensor_cpu)\n",
    "    loss = criterion(output, dummy_label)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Single training iteration completed.\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training time on CPU: 0.2967 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time_cpu = time.time()\n",
    "trials = 100\n",
    "for _ in range(trials):\n",
    "    output = model_cpu(input_tensor_cpu)\n",
    "    loss = criterion(output, dummy_label)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "end_time_cpu = time.time()\n",
    "avg_time_train_cpu = (end_time_cpu - start_time_cpu) / trials\n",
    "print(f\"Average training time on CPU: {avg_time_train_cpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Speedup: 6.32x\n",
      "Inference Speedup: 9.37x\n"
     ]
    }
   ],
   "source": [
    "# Speedup\n",
    "speedup = avg_time_train_cpu / avg_time_train_gpu\n",
    "print(f\"Train Speedup: {speedup:.2f}x\")\n",
    "speedup = avg_time_inference_cpu / avg_time_inference_gpu\n",
    "print(f\"Inference Speedup: {speedup:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
